# ğŸ“¦ Installation Guide - HG 585 LLM Evaluation System

Choose the installation option that best fits your needs and hardware capabilities.

## ğŸš€ Quick Start (Recommended)

### **Option 1: Minimal Installation** âš¡
**Best for**: Testing, basic functionality, limited hardware
**Size**: ~2-3GB
**Time**: 5-10 minutes

```bash
pip install -r requirements-minimal.txt
```

**What you get:**
- âœ… Document processing (HG585.pdf)
- âœ… Model downloading and management
- âœ… Basic training capabilities
- âœ… Interactive menu system
- âŒ Advanced evaluation metrics
- âŒ Professional visualizations
- âŒ Web interfaces

---

### **Option 2: Full Installation** ğŸ¯
**Best for**: Production use, complete evaluation, research
**Size**: ~8-10GB
**Time**: 15-30 minutes

```bash
pip install -r requirements-full.txt
```

**What you get:**
- âœ… Everything from minimal installation
- âœ… Advanced evaluation metrics (BLEU, ROUGE, etc.)
- âœ… Professional visualizations and charts
- âœ… Complete data science stack
- âœ… Enhanced document processing
- âœ… Performance optimizations

---

### **Option 3: Chat Interface Only** ğŸ’¬
**Best for**: Using already trained models, deployment
**Size**: ~3-4GB
**Time**: 10-15 minutes

```bash
pip install -r requirements-chat.txt
```

**What you get:**
- âœ… Model inference capabilities
- âœ… Web-based chat interfaces (Gradio, Streamlit)
- âœ… API server functionality
- âœ… Trained model deployment
- âŒ Training capabilities
- âŒ Document processing

---

## ğŸ® GPU Support

### **For NVIDIA GPUs (Recommended):**

#### **CUDA 11.8 (Most Compatible):**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

#### **CUDA 12.1 (Latest):**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### **Verify GPU Installation:**
```bash
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}, Devices: {torch.cuda.device_count()}')"
```

---

## ğŸ“‹ System Requirements

### **Minimal Installation:**
- **RAM**: 8GB+ (16GB recommended)
- **Storage**: 20GB+ free space
- **CPU**: 4+ cores
- **GPU**: Optional (CPU training supported)

### **Full Installation:**
- **RAM**: 16GB+ (32GB recommended)
- **Storage**: 50GB+ free space
- **CPU**: 8+ cores recommended
- **GPU**: NVIDIA with 8GB+ VRAM recommended

### **For GPU Training:**
- **NVIDIA GPU**: RTX 4060 Ti or better
- **VRAM**: 8GB minimum, 16GB+ recommended
- **CUDA**: 11.8 or 12.1
- **Drivers**: Latest NVIDIA drivers

---

## ğŸ› ï¸ Platform-Specific Setup

### **Windows:**
```cmd
# Run the automated setup
setup_windows.bat

# Or manual installation
pip install -r requirements-minimal.txt
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

### **Linux/macOS:**
```bash
# Run the automated setup
chmod +x gpu_setup.sh
./gpu_setup.sh

# Or manual installation
pip install -r requirements-minimal.txt
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ“Š Installation Comparison

| Feature | Minimal | Full | Chat Only |
|---------|---------|------|-----------|
| **Size** | 2-3GB | 8-10GB | 3-4GB |
| **Install Time** | 5-10 min | 15-30 min | 10-15 min |
| **Document Processing** | âœ… | âœ… | âŒ |
| **Model Training** | âœ… | âœ… | âŒ |
| **Basic Evaluation** | âœ… | âœ… | âŒ |
| **Advanced Metrics** | âŒ | âœ… | âŒ |
| **Visualizations** | âŒ | âœ… | âŒ |
| **Web Interfaces** | âŒ | âœ… | âœ… |
| **Model Inference** | âœ… | âœ… | âœ… |

---

## ğŸ”§ Troubleshooting

### **Common Issues:**

#### **"CUDA out of memory"**
```bash
# Use smaller batch size
# System automatically adjusts based on available VRAM
```

#### **"No module named 'torch'"**
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu118
```

#### **"Permission denied" on Windows**
```cmd
# Run Command Prompt as Administrator
# Or use setup_windows.bat
```

#### **Slow downloads**
```bash
# Install faster download support
pip install huggingface-hub[hf_xet]
```

---

## ğŸ’¡ Recommendations

### **For Beginners:**
1. Start with **Minimal Installation**
2. Test basic functionality
3. Upgrade to Full if needed

### **For Researchers:**
1. Use **Full Installation**
2. Install on GPU server
3. Enable all optimizations

### **For Deployment:**
1. Train with **Full Installation**
2. Deploy with **Chat Interface Only**
3. Use exported models

---

## ğŸ†˜ Support

- **System Status**: Run `python src/main.py` â†’ Option 9
- **GPU Check**: Run `nvidia-smi` (Windows/Linux)
- **Requirements Check**: Each requirements file includes size estimates
- **Performance Tips**: See README.md for hardware-specific optimizations

---

**Ready to start? Choose your installation option above! ğŸš€**
