# LLM Evaluation Comparison Report

Generated on: 2025-11-05 07:04:47

## Summary

- **Models Evaluated**: 1
- **Evaluation Stages**: training
- **Total Evaluations**: 1

## Metrics Comparison

| Model | Stage | Exact Match | F1 Score | Bleu Score | Rouge L | Semantic Similarity |
|-------|-------|-------|-------|-------|-------|-------|
| gpt_oss_before | training | 0.0000 | 0.0903 | 0.0000 | 0.0564 | 0.0491 |

## Training Improvement Analysis

## Detailed Results

### Gpt Oss Before Training

- **Model Path**: gpt-oss:20b
- **Evaluation Time**: 0.45 seconds
- **Number of Examples**: 98

**Metrics**:

- Answer Relevance: 0.0491
- Avg Prediction Length: 18.0000
- Avg Reference Length: 575.9286
- Bleu Score: 0.0000
- Evaluation Time: 0.4545
- Exact Match: 0.0000
- F1 Score: 0.0903
- Length Ratio: 0.0313
- Num Examples: 98.0000
- Question Answering Accuracy: 0.0405
- Romanian Accuracy: 0.5422
- Rouge L: 0.0564
- Semantic Similarity: 0.0491

